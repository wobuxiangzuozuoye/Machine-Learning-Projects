{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIb7Nui77r_v"
      },
      "source": [
        "# Lab 2. PyTorch models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tguz2M-kmnmi"
      },
      "source": [
        "---\n",
        "\n",
        "How to Use This Notebook\n",
        "---\n",
        "\n",
        "**Recommended Setup**\n",
        "- For the best experience, **run this notebook on [Google Colab](https://colab.research.google.com/)**—especially if your local machine is slow.  \n",
        "- In Colab, **enable GPU support** by going to:  \n",
        "  `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
        "\n",
        "\n",
        "**Homework Tasks**\n",
        "\n",
        " - Homework tasks are clearly marked throughout the notebook in the following format:\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > <span style=\"color:red\"><b>TASK X</b> - [<i>some text</i>]:</span>\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > ```Your code ....```\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > *End of Task X.* [*Instructions for passing*]\n",
        "\n",
        " - For each task:\n",
        "   - **Complete the code** where indicated.\n",
        "   - **Upload the required results** from each task to **Homework 2 – Code** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        " - Once you've finished all the tasks:\n",
        "   Submit your **entire completed notebook (including your code!)** to **Homework 2 – Notebook** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        "**Important:**  \n",
        "Your submission will **only be graded if both files** (code + notebook) are uploaded **before the deadline**. Late submissions are **not accepted**, regardless of technical issues like bad internet connection.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIH0AWH2_jxD"
      },
      "source": [
        "This lab will teach how to use PyTorch by making a simple neural network model. Regradless of model's complexity, creating any model can be completed in a similar way. We will use the **Fashion MNIST** dataset, one of the variants of the MNIST dataset. It has the same property as a normal MNIST, with the same size (28*28) and the same number of classes (10), but the images represent fashion items rather than handwritten digits, which means it might have more complexity than normal MNIST.\n",
        "\n",
        "Because of its complexity in each class, the problem is significantly more challenging than normal MNIST. For example, a simple linear model reaches about 92% accuracy on MNIST, but only about 83% on Fashion MNIST. Below is an example of Fashion MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gQUsFpCD0aP"
      },
      "source": [
        "\n",
        "![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBXx3rp8D2Nm"
      },
      "source": [
        "\n",
        "In today's lab, we will first try to create a simple fully connected network model and check its basic performance on Fashion MNIST.\n",
        "\n",
        "Based on your local machine's performance, the task might take a long time, so it is recommended to use the [Google Colab](https://colab.research.google.com/) since it can handle the lab contents with no processing bottleneck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ChFhB0bauM"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkiDj5c8beHt"
      },
      "source": [
        "- Import PyTorch and load a sample dataset\n",
        "- Sequential fully connected network\n",
        "- Other useful functions (Saving/Loading)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDXwomm0bxug"
      },
      "source": [
        "### Section 1: Import PyTorch and load a sample dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI9hfGXIA6Ek"
      },
      "source": [
        "You should be able to install PyTorch by using `pip`. You do not need to specify a GPU version."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "9RbyaN5InMea",
        "outputId": "e38de678-5d0c-4135-9242-2abca72d00d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f6456a2e-ab8a-4355-b634-0a4d229c601a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f6456a2e-ab8a-4355-b634-0a4d229c601a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data_test.csv to data_test.csv\n",
            "Saving data_train.csv to data_train.csv\n",
            "Saving description.md to description.md\n",
            "Saving labels_train.csv to labels_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzUBH9xhn0JL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install numpy torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y7mgvEN8mtN6"
      },
      "outputs": [],
      "source": [
        "import torch as pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "I8zL6JdKIasB"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1Ek6pMT_pdg_",
        "outputId": "d11ece01-db15-402c-a3a3-6d6e8dd74bfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# version?\n",
        "pt.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhFeXn8MgFT2"
      },
      "source": [
        "We will use the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) data available in github, which has 70,000 article images. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "Since it is on github we can simple get it by using `git clone [repo] [folder]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McfKi-cJn0JP",
        "outputId": "ef8427ee-7e5c-47b0-d8c4-5c25f7791748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 762, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 762 (delta 0), reused 2 (delta 0), pack-reused 758 (from 1)\u001b[K\n",
            "Receiving objects: 100% (762/762), 105.85 MiB | 41.83 MiB/s, done.\n",
            "Resolving deltas: 100% (444/444), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zalandoresearch/fashion-mnist data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6efgvJL-WwWu"
      },
      "source": [
        "#### Dataset handling: Traditional way with scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lga5zwx6BJti"
      },
      "source": [
        "Datasets can be found in diverse locations -- e.g. on [github](https://github.com/), [zenodo](https://zenodo.org/), [huggingface](https://huggingface.co/docs/hub/en/datasets), [kaggle](https://www.kaggle.com/datasets) or **your companies server**. Some Python modules like `torch` and `tensorflow` also have their own easy-to-use versions of standard datasets specialised to the specific library. For a fast, but less general alternative to this tutorial, see [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). **The linked tutorial is for interrested students and not part of this assignment!**\n",
        "\n",
        "If the dataset is hosted on github or similar, the first step is to check the description: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist#get-the-data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SSWdpC1tjnL"
      },
      "source": [
        "Lets check out the `mnist_reader` they mention:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpYgIPJnr4Cz",
        "outputId": "44b7b399-5f5e-4473-bb6c-652717767038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: type: datautilsmnist_reader.py: not found\n"
          ]
        }
      ],
      "source": [
        "!type data\\utils\\mnist_reader.py # windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-Nz93XtsRy"
      },
      "source": [
        "What values does the parameter `kind` take?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NXvbQYytQfW",
        "outputId": "caddc0fd-9bd0-4bb0-f7cb-c80b2f375cdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t10k-images-idx3-ubyte.gz',\n",
              " 'train-images-idx3-ubyte.gz',\n",
              " 't10k-labels-idx1-ubyte.gz',\n",
              " 'train-labels-idx1-ubyte.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os\n",
        "os.listdir('data/data/fashion')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpsK-umdt4pc"
      },
      "source": [
        "Let's load the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_i0BcD_qwx0"
      },
      "outputs": [],
      "source": [
        "# import mnist_reader:\n",
        "import data.utils.mnist_reader as mnist_reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2DoMiOnplgm"
      },
      "outputs": [],
      "source": [
        "# load data:\n",
        "X_train_full, y_train_full = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "X_test, y_test = mnist_reader.load_mnist('data/data/fashion', kind='t10k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9KfXaFeBQLY"
      },
      "source": [
        "This dataset is loaded as a NumPy array which we learned before in Lab 1. You can use all the methods you learned to check the properties of the dataset, like **shape** or **describe**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQGzWUZABSdD",
        "outputId": "4d64d2f5-923f-4656-b8aa-ec6ffd7de359"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# type?\n",
        "type(X_train_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA4f__FUppwQ",
        "outputId": "1817ad25-13d6-4caa-d3cc-965436ab3b61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# shape?\n",
        "X_train_full.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbRWMKbUZnJJ",
        "outputId": "968a6940-c6be-4967-8121-3fc995258705"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "np.unique(y_train_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeSk4-jABU95"
      },
      "source": [
        "As the dataset is composed of grayscale pixels, the datatype of it is unsigned integer. The dataset also has a pixed range [0, 255] so it does not need to take higher bit than 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdNJONOHptj6",
        "outputId": "02d72f51-d46d-4ce6-fe57-1e911b873df4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# dtype?\n",
        "X_train_full.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZE6WfngbYs"
      },
      "source": [
        "Besides that, PyTorch models are also usually evaluated by one more separate set called validation set as training is an iterative and time-consuming process and we do not know when we need to stop clearly. So we would like to estimate the right time to interrupt the training process by checking its performance for each iteration.\n",
        "\n",
        "To create a validation set, there can be many options, we can explicitly split the dataset using index, or we can just use a training set but with the option stating we want to validate, when we actually fit the model. However, this time we will use scikit-learn's `train_test_split` method to create a validation set as it can provide a nice stratification option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUEmqGNGoZ_W"
      },
      "source": [
        "We need a simiple normalization - as we all know the graysclae ranges from 0 to 255..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb6n6PzLgjRj"
      },
      "outputs": [],
      "source": [
        "# Introduced in the coursebook\n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azOEHFspR7u5"
      },
      "outputs": [],
      "source": [
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtvJAWxvhEP"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 1</b> - Stratified Split:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Replace the above simple training/validation split with a **stratified** one (50% train, 50% validation):\n",
        "  - Use `X_train_full` and `y_train_full`\n",
        "  - Enable `shuffle` and `stratification`\n",
        "\n",
        "Use [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Print and check their shapes afterward!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQuXXouFLDRN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# normalize:\n",
        "X_train_full = X_train_full / 255.\n",
        "\n",
        "# split data:\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.5, stratify=y_train_full, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4gVzDXcR7u7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78701dde-28f7-4364-d13b-7b8b428adb02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (30000, 784)\n",
            "X_valid shape: (30000, 784)\n",
            "y_train shape: (30000,)\n",
            "y_valid shape: (30000,)\n"
          ]
        }
      ],
      "source": [
        "# shape?\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_valid shape:\", X_valid.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_valid shape:\", y_valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_f0SkwQR7u7"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 1. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWTSsrnEF2XC"
      },
      "source": [
        "Here we prepared the class names of the fashion MNIST dataset for your convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRc7tKoIsFx4"
      },
      "outputs": [],
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eBOMMsxAxrfj",
        "outputId": "01d860b7-5e41-47bf-991b-a8c6c7729b94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T-shirt/top'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Use the numeric label to get the class name, e.g:\n",
        "class_names[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch49P29iEDxC"
      },
      "source": [
        "We can also try to see each data instance by using **plt.imshow**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "FSwEtbA6KmFg",
        "outputId": "84fa229f-8634-4a60-d575-f62802f7b971"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i = np.random.randint(0, X_train.shape[0])\n",
        "plt.imshow(X_train[i].reshape((28, 28)), cmap='gray') # cmap to make it recognize grayscale\n",
        "plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngPR-OZKyStX"
      },
      "source": [
        "#### Optimizing memory consuption using pipelines:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2w2ohRDo2eW"
      },
      "source": [
        "Imagine taking the above approach with very large datasets (e.g. used for training modern LLMs). Loading all the data before training would exceed RAM and VRAM of almost any computer.\n",
        "\n",
        "Therefore, we are going to use the [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) API:\n",
        "\n",
        "---\n",
        "***An abstract class representing a Dataset.***\n",
        "\n",
        "*All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite* `__getitem__()`*, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite* `__len__()`*, which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader. Subclasses could also optionally implement* `__getitems__()`*, for speedup batched samples loading. This method accepts list of indices of samples of batch and returns list of samples.*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcvyxGDerVFS"
      },
      "outputs": [],
      "source": [
        "from numpy.typing import NDArray\n",
        "from typing import Tuple\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, X:NDArray[np.int8], y:NDArray[np.int8]) -> None:\n",
        "    # normalize:\n",
        "    self.X = X.astype(np.float32) / 255.0\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx:int) -> int:\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "\n",
        "    # load data:\n",
        "    train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "    t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "    data   = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "    labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "    # split data:\n",
        "    n = len(labels)\n",
        "    n_train = int(n * fraction_train)\n",
        "    n_validation = int(n * fraction_validation)\n",
        "\n",
        "    data_train = FashionMNIST(\n",
        "        data[:n_train],\n",
        "        labels[:n_train]\n",
        "    )\n",
        "    data_valid = FashionMNIST(\n",
        "        data[n_train:n_train+n_validation],\n",
        "        labels[n_train:n_train+n_validation]\n",
        "    )\n",
        "    data_test = FashionMNIST(\n",
        "        data[n_train+n_validation:],\n",
        "        labels[n_train+n_validation:]\n",
        "    )\n",
        "\n",
        "    return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0v0JjVOk57s"
      },
      "source": [
        "It works like a list of tuples `(X, y)` in Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCOTVO81lZyD"
      },
      "outputs": [],
      "source": [
        "data, _, _ = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOjOC4aIlpfp",
        "outputId": "cd2ba6a3-dc40-4e1c-a83a-de53bd4f716e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# call to __len__:\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILFLbrYUlrdL",
        "outputId": "04621bfc-9aa0-4c55-933e-f223298151bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
              "        0.34509805, 0.7372549 , 0.6745098 , 0.5176471 , 0.49019608,\n",
              "        0.5529412 , 0.78039217, 0.56078434, 0.03529412, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.        , 0.07843138,\n",
              "        0.5137255 , 0.78039217, 0.80784315, 0.76862746, 0.7921569 ,\n",
              "        0.9490196 , 1.        , 1.        , 0.98039216, 0.87058824,\n",
              "        0.77254903, 0.80784315, 0.7372549 , 0.49411765, 0.06666667,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.13725491, 0.8392157 , 0.7490196 , 0.7176471 ,\n",
              "        0.69803923, 0.6862745 , 0.65882355, 0.5882353 , 0.63529414,\n",
              "        0.62352943, 0.59607846, 0.61960787, 0.7019608 , 0.7176471 ,\n",
              "        0.7411765 , 0.7647059 , 0.7254902 , 0.32156864, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.6666667 ,\n",
              "        0.74509805, 0.6745098 , 0.69411767, 0.6901961 , 0.67058825,\n",
              "        0.6627451 , 0.63529414, 0.60784316, 0.5803922 , 0.6039216 ,\n",
              "        0.6627451 , 0.68235296, 0.6862745 , 0.6862745 , 0.69411767,\n",
              "        0.7176471 , 0.7372549 , 0.04705882, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.09803922, 0.7607843 , 0.7058824 , 0.69803923,\n",
              "        0.68235296, 0.72156864, 0.73333335, 0.7411765 , 0.73333335,\n",
              "        0.72156864, 0.70980394, 0.7411765 , 0.78431374, 0.77254903,\n",
              "        0.75686276, 0.74509805, 0.69803923, 0.6862745 , 0.7607843 ,\n",
              "        0.3529412 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.16470589,\n",
              "        0.85490197, 0.7490196 , 0.77254903, 0.8156863 , 0.8       ,\n",
              "        0.827451  , 0.81960785, 0.8235294 , 0.83137256, 0.827451  ,\n",
              "        0.8392157 , 0.84313726, 0.8352941 , 0.8392157 , 0.827451  ,\n",
              "        0.827451  , 0.7490196 , 0.78431374, 0.61960787, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34509805, 0.8666667 , 0.84313726,\n",
              "        0.8509804 , 0.85882354, 0.827451  , 0.7254902 , 0.5882353 ,\n",
              "        0.4627451 , 0.41960785, 0.3882353 , 0.34509805, 0.3254902 ,\n",
              "        0.3529412 , 0.5294118 , 0.83137256, 0.79607844, 0.8117647 ,\n",
              "        0.85882354, 0.6627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10588235, 0.4627451 , 0.63529414, 0.15686275,\n",
              "        0.        , 0.        , 0.        , 0.03921569, 0.07450981,\n",
              "        0.10980392, 0.15294118, 0.18431373, 0.14117648, 0.        ,\n",
              "        0.        , 0.79607844, 0.9019608 , 0.8627451 , 0.79607844,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.5411765 , 0.53333336,\n",
              "        0.2784314 , 0.27058825, 0.21176471, 0.84705883, 0.8509804 ,\n",
              "        0.79607844, 0.72156864, 0.65882355, 0.6392157 , 0.63529414,\n",
              "        0.6392157 , 0.69803923, 0.8666667 , 0.7294118 , 0.14901961,\n",
              "        0.10196079, 0.02745098, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.2627451 , 0.5254902 , 0.6039216 , 0.8784314 ,\n",
              "        0.5058824 , 0.25882354, 0.31764707, 0.45882353, 0.5058824 ,\n",
              "        0.5019608 , 0.5176471 , 0.5372549 , 0.5137255 , 0.5058824 ,\n",
              "        0.3372549 , 0.28627452, 0.6156863 , 0.5921569 , 0.5254902 ,\n",
              "        0.84705883, 0.07058824, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.79607844,\n",
              "        0.7764706 , 0.6745098 , 0.7176471 , 0.80784315, 1.        ,\n",
              "        1.        , 0.98039216, 0.9529412 , 0.9411765 , 0.9372549 ,\n",
              "        0.92156863, 0.93333334, 0.95686275, 1.        , 0.93333334,\n",
              "        0.72156864, 0.627451  , 0.3372549 , 0.38431373, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.47843137, 0.7372549 , 0.8784314 ,\n",
              "        0.5921569 , 0.4117647 , 0.49803922, 0.38039216, 0.39215687,\n",
              "        0.4117647 , 0.44705883, 0.45882353, 0.45882353, 0.44313726,\n",
              "        0.40392157, 0.38431373, 0.43529412, 0.5568628 , 0.99607843,\n",
              "        0.7490196 , 1.        , 0.19215687, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.6392157 , 0.7019608 , 0.78431374, 0.37254903, 0.6039216 ,\n",
              "        0.7764706 , 0.77254903, 0.78431374, 0.78431374, 0.7764706 ,\n",
              "        0.77254903, 0.7764706 , 0.78039217, 0.7921569 , 0.78431374,\n",
              "        0.6901961 , 0.3372549 , 0.80784315, 0.6156863 , 0.63529414,\n",
              "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.77254903, 0.7882353 ,\n",
              "        0.8980392 , 0.2784314 , 0.5647059 , 0.7607843 , 0.70980394,\n",
              "        0.7176471 , 0.7019608 , 0.7137255 , 0.7058824 , 0.7019608 ,\n",
              "        0.7058824 , 0.74509805, 0.7254902 , 0.77254903, 0.29803923,\n",
              "        0.85882354, 0.7254902 , 0.7882353 , 0.13333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.78039217, 0.75686276, 0.8862745 , 0.22745098,\n",
              "        0.6039216 , 0.7529412 , 0.72156864, 0.73333335, 0.72156864,\n",
              "        0.7294118 , 0.72156864, 0.7254902 , 0.7176471 , 0.7529412 ,\n",
              "        0.7490196 , 0.78431374, 0.21960784, 0.85882354, 0.79607844,\n",
              "        0.8117647 , 0.23529412, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.7882353 ,\n",
              "        0.7607843 , 0.8784314 , 0.16078432, 0.6392157 , 0.74509805,\n",
              "        0.7294118 , 0.7294118 , 0.72156864, 0.7254902 , 0.7176471 ,\n",
              "        0.7254902 , 0.69803923, 0.74509805, 0.7607843 , 0.7921569 ,\n",
              "        0.12941177, 0.827451  , 0.78431374, 0.80784315, 0.28627452,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.7882353 , 0.77254903, 0.87058824,\n",
              "        0.06666667, 0.6745098 , 0.74509805, 0.7294118 , 0.73333335,\n",
              "        0.7137255 , 0.7294118 , 0.7254902 , 0.73333335, 0.7058824 ,\n",
              "        0.73333335, 0.75686276, 0.7921569 , 0.10196079, 0.83137256,\n",
              "        0.7921569 , 0.79607844, 0.29803923, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.78431374, 0.77254903, 0.8745098 , 0.        , 0.69411767,\n",
              "        0.7411765 , 0.72156864, 0.7254902 , 0.69803923, 0.72156864,\n",
              "        0.7176471 , 0.72156864, 0.7058824 , 0.7176471 , 0.7411765 ,\n",
              "        0.79607844, 0.13725491, 0.76862746, 0.79607844, 0.79607844,\n",
              "        0.32941177, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.78431374, 0.77254903,\n",
              "        0.8745098 , 0.        , 0.7254902 , 0.73333335, 0.7254902 ,\n",
              "        0.73333335, 0.7058824 , 0.72156864, 0.7137255 , 0.7176471 ,\n",
              "        0.69803923, 0.7137255 , 0.7176471 , 0.8039216 , 0.17254902,\n",
              "        0.62352943, 0.8117647 , 0.7882353 , 0.33333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.73333335, 0.7764706 , 0.88235295, 0.        ,\n",
              "        0.7607843 , 0.7372549 , 0.72156864, 0.7254902 , 0.7058824 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.70980394, 0.70980394,\n",
              "        0.69411767, 0.80784315, 0.18039216, 0.5058824 , 0.827451  ,\n",
              "        0.78431374, 0.34509805, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02352941, 0.7294118 ,\n",
              "        0.78431374, 0.827451  , 0.        , 0.78039217, 0.7411765 ,\n",
              "        0.72156864, 0.72156864, 0.7254902 , 0.7137255 , 0.7176471 ,\n",
              "        0.72156864, 0.7254902 , 0.7137255 , 0.6862745 , 0.8039216 ,\n",
              "        0.19607843, 0.38039216, 0.84705883, 0.77254903, 0.3647059 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01960784, 0.7254902 , 0.8       , 0.72156864,\n",
              "        0.        , 0.7921569 , 0.7372549 , 0.7137255 , 0.7137255 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.7137255 , 0.7058824 ,\n",
              "        0.7137255 , 0.68235296, 0.7921569 , 0.24705882, 0.23137255,\n",
              "        0.8627451 , 0.76862746, 0.36862746, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
              "        0.72156864, 0.80784315, 0.6156863 , 0.        , 0.8       ,\n",
              "        0.73333335, 0.73333335, 0.7411765 , 0.7529412 , 0.74509805,\n",
              "        0.74509805, 0.7490196 , 0.74509805, 0.73333335, 0.7176471 ,\n",
              "        0.7921569 , 0.30588236, 0.13725491, 0.87058824, 0.77254903,\n",
              "        0.37254903, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01960784, 0.7176471 , 0.8156863 ,\n",
              "        0.49803922, 0.        , 0.77254903, 0.6509804 , 0.6       ,\n",
              "        0.58431375, 0.58431375, 0.57254905, 0.5803922 , 0.58431375,\n",
              "        0.5882353 , 0.5921569 , 0.61960787, 0.7490196 , 0.3529412 ,\n",
              "        0.03137255, 0.8745098 , 0.7647059 , 0.3882353 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.72156864, 0.8156863 , 0.44705883, 0.        ,\n",
              "        0.8       , 0.6784314 , 0.6313726 , 0.7058824 , 0.6901961 ,\n",
              "        0.6745098 , 0.6784314 , 0.6784314 , 0.68235296, 0.6901961 ,\n",
              "        0.63529414, 0.7921569 , 0.4509804 , 0.        , 0.8980392 ,\n",
              "        0.78039217, 0.4117647 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.03529412, 0.69803923,\n",
              "        0.8       , 0.4509804 , 0.        , 0.4745098 , 0.5294118 ,\n",
              "        0.44705883, 0.45882353, 0.44705883, 0.44705883, 0.45882353,\n",
              "        0.4627451 , 0.46666667, 0.45882353, 0.44313726, 0.5764706 ,\n",
              "        0.24705882, 0.        , 0.88235295, 0.76862746, 0.41960785,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.7058824 , 0.80784315, 0.5137255 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.8784314 , 0.77254903, 0.48235294, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.5529412 , 0.5921569 , 0.29803923, 0.        , 0.00392157,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.52156866, 0.654902  ,\n",
              "        0.28627452, 0.        , 0.        , 0.        ], dtype=float32),\n",
              " np.uint8(2))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# call to __getitem__:\n",
        "data[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1u-U7X-fXCB"
      },
      "source": [
        "But the above implementation still loads everything at the time of instantiation of the `FashionMNIST` class. So let's transform the data into a format that you see more often with big datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EADlbbqB01Kw"
      },
      "outputs": [],
      "source": [
        "# unzip data:\n",
        "target_dir = 'data/data/fashion/unzipped'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "data = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "for i, x in enumerate(data):\n",
        "  file = os.path.join(target_dir, f'img_{i:d}.npy')\n",
        "  with open(file, 'wb') as f:\n",
        "    np.save(f, x.reshape((28, 28)))\n",
        "\n",
        "with open(os.path.join(target_dir, 'labels.npy'), 'wb') as f:\n",
        "  np.save(f, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv0YptsZ-QaG",
        "outputId": "04d67e85-9780-4899-9551-9459ff1dcfd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['img_67431.npy',\n",
              " 'img_4951.npy',\n",
              " 'img_1250.npy',\n",
              " 'img_41482.npy',\n",
              " 'img_8223.npy',\n",
              " 'img_6140.npy',\n",
              " 'img_35312.npy',\n",
              " 'img_55257.npy',\n",
              " 'img_56894.npy',\n",
              " 'img_19954.npy']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "os.listdir(target_dir)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrICJqXvjc1Y"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 2</b> - Dataset:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Complete the following class.\n",
        "- It should load every single sample dynamically from disk when it is requested and this way keep memory consumption to a minimum.\n",
        "- Use your code from Task 1 to create stratified splits using the `stratify` and `shuffle` arguments of `create_split`.\n",
        "- Use the variable `target_dir` as the path to the unzipped data.\n",
        "- **Make sure it produces the the right type of outputs (see type hintig and class above)!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmiKviaXkHYb"
      },
      "outputs": [],
      "source": [
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, indices:NDArray[np.int32], labels:NDArray[np.int8]) -> None:\n",
        "    self.indices = indices\n",
        "    self.labels  = labels\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.indices)\n",
        "\n",
        "  def __getitem__(self, idx:int) -> int:\n",
        "    file = os.path.join(target_dir, f'img_{self.indices[idx]:d}.npy')\n",
        "    with open(file, 'rb') as f:\n",
        "      X = np.load(f).astype(np.float32) / 255.0\n",
        "    y = self.labels[idx]\n",
        "\n",
        "    return X, y\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float, stratify:bool=True, shuffle:bool=True) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "    # load labels:\n",
        "    with open(os.path.join(target_dir, 'labels.npy'), 'rb') as f:\n",
        "      labels = np.load(f)\n",
        "\n",
        "    # create indices:\n",
        "    indices = np.arange(len(labels))\n",
        "\n",
        "    # split data:\n",
        "    strat = labels if stratify else None # this is equivalent to stratify=labels if stratify==True else None\n",
        "    indices_train, indices_rest, labels_train, labels_rest = train_test_split(indices, labels, test_size=1-fraction_train, stratify=strat, shuffle=shuffle, random_state=42)\n",
        "    strat = labels_rest if stratify else None\n",
        "    indices_valid, indices_test, labels_valid, labels_test = train_test_split(indices_rest, labels_rest, test_size=fraction_test/(fraction_validation+fraction_test), stratify=strat, shuffle=shuffle, random_state=42)\n",
        "\n",
        "    data_train = FashionMNIST(indices_train, labels_train)\n",
        "    data_valid = FashionMNIST(indices_valid, labels_valid)\n",
        "    data_test = FashionMNIST(indices_test, labels_test)\n",
        "\n",
        "    return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQxU6CLfR7vD"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 2. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRzLUn4kGGVU"
      },
      "source": [
        "Our objective is to create a model with the high accuracy on this dataset. Let's start to create our first model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ox0oodObDPH"
      },
      "source": [
        "**Shuffling and batching**: Using [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), you can easily shuffle and batch the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdYJGAsARQxB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZmqQ9W2pp5b"
      },
      "outputs": [],
      "source": [
        "data_train, data_valid, data_test = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2dJNcKrESEU"
      },
      "outputs": [],
      "source": [
        "loader_train = DataLoader(data_train,             # dataset from which to load the data.\n",
        "                          batch_size=BATCH_SIZE,  # how many samples per batch to load (default: 1).\n",
        "                          shuffle=True,           # set to True to have the data reshuffled at every epoch (default: False).\n",
        "                          sampler=None,           # defines the strategy to draw samples from the dataset. Can be any Iterable with __len__ implemented.\n",
        "                                                  # If specified, shuffle must not be specified.\n",
        "                          batch_sampler=None,     # like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
        "                          drop_last=False)        # set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size.\n",
        "                                                  # If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj964nU9EVbq"
      },
      "outputs": [],
      "source": [
        "# validation set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_valid = DataLoader(data_valid,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu56t0MPO1PF"
      },
      "outputs": [],
      "source": [
        "# test set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_test  = DataLoader(data_test,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewz-SbwJxZ1t"
      },
      "source": [
        "### Section 2: Sequential fully connected network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fh7PjMWqOnS"
      },
      "source": [
        "#### Instantiating the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGuxZ7HZgpwm"
      },
      "source": [
        "The standard way to create a PyTorch model is to override the [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class. To create a model you need to override the following methods:\n",
        "- `__init__(self, ...) -> None`: Initializes the module and instantiates all the layers and functions.\n",
        "- `forward(self, x) -> y`: implements the forward pass through the network.\n",
        "\n",
        "When you create a layer (e.g. [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)), you should specify **in_features** and **out_features**. Don't forget to apply an **activation function** in the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpDMjCbExvzN"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(in_features=784, out_features=100, bias=True)\n",
        "        self.layer2 = nn.Linear(in_features=100, out_features=len(class_names), bias=True)\n",
        "\n",
        "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
        "        x = F.relu(self.layer1(x))\n",
        "        return F.softmax(self.layer2(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvjomL9CJcrr"
      },
      "source": [
        "We can visualize the model using **keras.utils.plot_model**. It helps to figue out (or validate) the structure of complete models having multiple paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iLn73SNJenS",
        "outputId": "02c30e52-39e7-4172-aaa5-f6a064ac8185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "            Linear-2                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = CustomNetwork()\n",
        "summary(model, input_size=(784,), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_iVtGfSEe7b"
      },
      "source": [
        "Summarization of model parameters is only possible when the model has an input information as it needs to calculate the fully connected parameters from the input layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEOcLYKLEpgw"
      },
      "source": [
        "A model instance has various attributes to get layers, weights - which are just for your reference to check the real values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5iYpVqcwYL9",
        "outputId": "f1ecbe7b-256e-48d7-f716-d64ed0970e45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=100, bias=True),\n",
              " Linear(in_features=100, out_features=10, bias=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# You can get a generator object of properties of type `torch.nn.Module` using `children()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFwCNTJ4nGyW",
        "outputId": "bd7187fe-e477-4054-c77d-abdaa1a8b617"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "list(model.named_children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJcb7xZtpEAZ",
        "outputId": "449e8abe-5496-40e6-de05-22a3f4084489"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=100, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model.get_submodule('layer1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdnS08_Lom1s",
        "outputId": "9422e902-a260-4337-85f4-3a2b1ac0c940"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('',\n",
              "  CustomNetwork(\n",
              "    (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
              "    (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )),\n",
              " ('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# All modules in the model (including itself):\n",
        "list(model.named_modules())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAa1OQuPnlNF",
        "outputId": "3edc01b5-fe5c-47e2-cede-d5aee4a9af9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0333, -0.0074,  0.0135,  ..., -0.0142, -0.0087, -0.0157],\n",
              "         [ 0.0327, -0.0333,  0.0032,  ..., -0.0159, -0.0129, -0.0085],\n",
              "         [ 0.0353,  0.0230,  0.0178,  ...,  0.0037,  0.0246, -0.0022],\n",
              "         ...,\n",
              "         [ 0.0166, -0.0115, -0.0008,  ...,  0.0008, -0.0192, -0.0125],\n",
              "         [-0.0109,  0.0147,  0.0046,  ..., -0.0112,  0.0166, -0.0070],\n",
              "         [ 0.0279,  0.0185,  0.0160,  ..., -0.0156, -0.0347, -0.0203]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0300,  0.0002,  0.0156, -0.0318,  0.0261, -0.0107, -0.0253,  0.0019,\n",
              "         -0.0091, -0.0176,  0.0311, -0.0247,  0.0046, -0.0114, -0.0081,  0.0321,\n",
              "          0.0220,  0.0114,  0.0165, -0.0341,  0.0067,  0.0143, -0.0255,  0.0155,\n",
              "         -0.0339, -0.0028,  0.0200,  0.0278,  0.0212, -0.0337, -0.0156,  0.0066,\n",
              "          0.0044,  0.0193, -0.0044,  0.0122,  0.0166,  0.0029,  0.0043,  0.0303,\n",
              "         -0.0164, -0.0356, -0.0207,  0.0195,  0.0337,  0.0338, -0.0338,  0.0009,\n",
              "         -0.0150, -0.0005,  0.0144, -0.0045, -0.0070, -0.0126, -0.0151,  0.0278,\n",
              "          0.0343, -0.0238,  0.0170,  0.0122, -0.0094,  0.0219, -0.0099, -0.0303,\n",
              "          0.0280, -0.0289,  0.0297,  0.0143,  0.0058,  0.0159,  0.0152,  0.0059,\n",
              "         -0.0208, -0.0026,  0.0171, -0.0264, -0.0318, -0.0231,  0.0151,  0.0023,\n",
              "         -0.0116, -0.0146,  0.0249,  0.0154, -0.0120, -0.0179,  0.0353, -0.0014,\n",
              "          0.0349,  0.0121, -0.0260,  0.0066,  0.0004, -0.0111,  0.0055,  0.0264,\n",
              "         -0.0025, -0.0115, -0.0097, -0.0039], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# You can get a generator object of parameters (weights) for each submodule using `parameters()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUW334iaoA7z",
        "outputId": "beb55701-047f-4952-9bcc-942bd5c46dda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layer1.weight',\n",
              "  Parameter containing:\n",
              "  tensor([[-0.0333, -0.0074,  0.0135,  ..., -0.0142, -0.0087, -0.0157],\n",
              "          [ 0.0327, -0.0333,  0.0032,  ..., -0.0159, -0.0129, -0.0085],\n",
              "          [ 0.0353,  0.0230,  0.0178,  ...,  0.0037,  0.0246, -0.0022],\n",
              "          ...,\n",
              "          [ 0.0166, -0.0115, -0.0008,  ...,  0.0008, -0.0192, -0.0125],\n",
              "          [-0.0109,  0.0147,  0.0046,  ..., -0.0112,  0.0166, -0.0070],\n",
              "          [ 0.0279,  0.0185,  0.0160,  ..., -0.0156, -0.0347, -0.0203]],\n",
              "         requires_grad=True)),\n",
              " ('layer1.bias',\n",
              "  Parameter containing:\n",
              "  tensor([-0.0300,  0.0002,  0.0156, -0.0318,  0.0261, -0.0107, -0.0253,  0.0019,\n",
              "          -0.0091, -0.0176,  0.0311, -0.0247,  0.0046, -0.0114, -0.0081,  0.0321,\n",
              "           0.0220,  0.0114,  0.0165, -0.0341,  0.0067,  0.0143, -0.0255,  0.0155,\n",
              "          -0.0339, -0.0028,  0.0200,  0.0278,  0.0212, -0.0337, -0.0156,  0.0066,\n",
              "           0.0044,  0.0193, -0.0044,  0.0122,  0.0166,  0.0029,  0.0043,  0.0303,\n",
              "          -0.0164, -0.0356, -0.0207,  0.0195,  0.0337,  0.0338, -0.0338,  0.0009,\n",
              "          -0.0150, -0.0005,  0.0144, -0.0045, -0.0070, -0.0126, -0.0151,  0.0278,\n",
              "           0.0343, -0.0238,  0.0170,  0.0122, -0.0094,  0.0219, -0.0099, -0.0303,\n",
              "           0.0280, -0.0289,  0.0297,  0.0143,  0.0058,  0.0159,  0.0152,  0.0059,\n",
              "          -0.0208, -0.0026,  0.0171, -0.0264, -0.0318, -0.0231,  0.0151,  0.0023,\n",
              "          -0.0116, -0.0146,  0.0249,  0.0154, -0.0120, -0.0179,  0.0353, -0.0014,\n",
              "           0.0349,  0.0121, -0.0260,  0.0066,  0.0004, -0.0111,  0.0055,  0.0264,\n",
              "          -0.0025, -0.0115, -0.0097, -0.0039], requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "list(model.named_parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyjmrnDXobxo",
        "outputId": "1d0dde89-cc9a-46de-e2cb-598d790c6b90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0333, -0.0074,  0.0135,  ..., -0.0142, -0.0087, -0.0157],\n",
              "        [ 0.0327, -0.0333,  0.0032,  ..., -0.0159, -0.0129, -0.0085],\n",
              "        [ 0.0353,  0.0230,  0.0178,  ...,  0.0037,  0.0246, -0.0022],\n",
              "        ...,\n",
              "        [ 0.0166, -0.0115, -0.0008,  ...,  0.0008, -0.0192, -0.0125],\n",
              "        [-0.0109,  0.0147,  0.0046,  ..., -0.0112,  0.0166, -0.0070],\n",
              "        [ 0.0279,  0.0185,  0.0160,  ..., -0.0156, -0.0347, -0.0203]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model.get_parameter('layer1.weight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06cXyZlQwJca"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 3</b> - Simple Network:</span>\n",
        "\n",
        "---\n",
        "\n",
        "The above network is very simple. Implement a better version with the following layers:\n",
        "- One **linear input layer** of 300 perceptrons, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear hidden layer** of size 200, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear output layer**, with a **softmax** activation function.\n",
        "\n",
        "Assume that `torch.nn` is already imported as `nn`. Furthermore, `torch.nn.functional` is available as `F`.\n",
        "Make sure the network has the following layers (i.e. use `torch.nn.Dropout` instead of `torch.nn.functional.dropout`):\n",
        "\n",
        "    --------------------------\n",
        "            Layer (type)      \n",
        "    ==========================\n",
        "             Linear-1         \n",
        "            Dropout-2         \n",
        "             Linear-3         \n",
        "            Dropout-4         \n",
        "             Linear-5         \n",
        "    ==========================\n",
        "    Total params: 297,710     \n",
        "    Trainable params: 297,710\n",
        "    Non-trainable params: 0   \n",
        "    --------------------------\n",
        "\n",
        "See [here](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) for documentation of the `torch.nn.Dropout` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpYsDHgzwuwI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 300)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc2 = nn.Linear(300, 200)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc3 = nn.Linear(200, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.softmax(self.fc3(x), dim=1)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yN435-5R7vM"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 3. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg8n20famnm2"
      },
      "source": [
        "**Alternative but more restrictive:** `torch.nn.Sequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIuFdlVhmnm2"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Sequential\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Irgjqdkmnm2"
      },
      "source": [
        "Unnamed layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvST9kW9mnm3"
      },
      "outputs": [],
      "source": [
        "model = Sequential(\n",
        "    nn.Linear(in_features=784, out_features=100, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=100, out_features=len(class_names), bias=True),\n",
        "    nn.Softmax(dim=-1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHq11P1Omnm3"
      },
      "source": [
        "Named layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI3mD5oRmnm3"
      },
      "outputs": [],
      "source": [
        "model = Sequential(OrderedDict([\n",
        "    ('layer1',      nn.Linear(in_features=784, out_features=100, bias=True)),\n",
        "    ('activation1', nn.ReLU()),\n",
        "    ('layer2',      nn.Linear(in_features=100, out_features=len(class_names), bias=True)),\n",
        "    ('activation2', nn.Softmax(dim=-1))\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wi6UT5CyNH1",
        "outputId": "51ca4836-69f1-4986-e867-ead5900f43bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (activation1): ReLU()\n",
            "  (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (activation2): Softmax(dim=-1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWo7nYEYp-Wb"
      },
      "source": [
        "### Section 3: Training the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Q14ZHssu1E"
      },
      "source": [
        "In PyTorch one needs to define which device to use for computation. All tensors involved in the computation need to be on that device. The most common devices are:\n",
        "- `cpu`: any of your computer's CPUs\n",
        "- `cpu:0`:the first of your computer's CPUs\n",
        "- `cuda`: any of your computer's GPUs\n",
        "- `cuda:2`: the third GPU of you computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9HxsXGisi9T",
        "outputId": "9fba441b-d695-40fa-eac6-913599edc636"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "# get gpu if available else cpu:\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs-4FS3uKsMZ"
      },
      "outputs": [],
      "source": [
        "# move a model or tensor to the device:\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuZAZKxtFBFR"
      },
      "source": [
        "Prediction on new instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdDh74y0i7fX",
        "outputId": "612b04df-b69a-498d-d0dd-b010e3409a4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13285276, 0.0990706 , 0.10820825, 0.10181213, 0.08378466,\n",
              "        0.1019468 , 0.08382646, 0.09259874, 0.0983474 , 0.09755214],\n",
              "       [0.15050186, 0.11956564, 0.11294729, 0.1058016 , 0.07224836,\n",
              "        0.10081984, 0.07455402, 0.07735439, 0.08545536, 0.10075162],\n",
              "       [0.10014328, 0.10707834, 0.12100883, 0.10323314, 0.07252984,\n",
              "        0.09042562, 0.09370496, 0.11636176, 0.08720472, 0.10830951]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "X_new = pt.tensor(X_test[:3], dtype=pt.float32, device=device)\n",
        "y_proba = model(X_new) # this returns a probability?\n",
        "y_proba = y_proba.detach().cpu().numpy() # to numpy\n",
        "y_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU8cAN3fi99y",
        "outputId": "cd12adbb-4b86-4b12-8028-ea4859f0ff1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['T-shirt/top', 'T-shirt/top', 'Pullover'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "np.array(class_names)[np.argmax(y_proba, axis=1)] #if we want to know the class names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9wLOuG8vK_r"
      },
      "source": [
        "Instances of `torch.nn.Module` have a method `.train()` and a method `.eval()` that set the whole module (including submodules) in a training or prediction mode.\n",
        "\n",
        "This is necessary, as for example dropout layers are inactive during prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIRxMYLRqnoU"
      },
      "source": [
        "In order to train the network, we need to define a training procedure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqjxNg_mDP2z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from typing import Optional, Callable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBxz4ZXkz4hT"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  # 1. set model to train:\n",
        "  model.train()\n",
        "\n",
        "  losses = None if loss_fn is None else []\n",
        "  with pt.enable_grad():\n",
        "    for X_batch, y_batch in loader_train:\n",
        "      # move tensors to correct device:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      # reset all gradients to zero:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # create predictions:\n",
        "      y_pred = model(X_batch)\n",
        "\n",
        "      # calculate loss:\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "      # backpropagate loss:\n",
        "      loss.backward()\n",
        "\n",
        "      # update weights:\n",
        "      optimizer.step()\n",
        "\n",
        "  return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adSjw6i50L3b"
      },
      "outputs": [],
      "source": [
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "  # 1. set model to eval:\n",
        "  model.eval()\n",
        "\n",
        "  labels = []\n",
        "  predictions = []\n",
        "  losses = None if loss_fn is None else []\n",
        "  for X_batch, y_batch in loader_valid:\n",
        "    # move tensors to correct device:\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    labels.extend(y_batch.cpu().detach().numpy())\n",
        "\n",
        "    # create predictions:\n",
        "    y_pred = model(X_batch)\n",
        "    predictions.extend(y_pred.cpu().detach().numpy())\n",
        "\n",
        "    # calculate loss:\n",
        "    if loss_fn is not None:\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "  # calculate f1 score:\n",
        "  f1 = f1_score(\n",
        "    y_batch.cpu().detach().numpy(),\n",
        "    y_pred.argmax(dim=1).cpu().detach().numpy(),\n",
        "    average='macro'\n",
        "  )\n",
        "\n",
        "  if loss_fn is None: return {'f1':f1}\n",
        "  else: return {'loss':np.mean(losses), 'f1':f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SASZ5PCXq4tr"
      },
      "outputs": [],
      "source": [
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float):\n",
        "  # instantiate optimizer:\n",
        "  optimizer = pt.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  # instantiate loss function:\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  history = []\n",
        "  for i in range(epochs):\n",
        "    # train for one epoch:\n",
        "    loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "\n",
        "    # evaluate on validation:\n",
        "    metrics = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "    # save metrics:\n",
        "    history.append({\n",
        "      'loss_train':loss_train,\n",
        "      'loss_valid': metrics['loss'],\n",
        "      'f1_valid': metrics['f1']\n",
        "    })\n",
        "\n",
        "    # print message:\n",
        "    print(f'Epoch {i+1:d}/{epochs:d}:', *[f'{metric} = {history[-1][metric]:.2f};' for metric in history[-1]], sep='\\t')\n",
        "\n",
        "  # return history:\n",
        "  return pd.DataFrame(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08uZrmWMCmq"
      },
      "source": [
        "Fit the model for 30 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U1VqXewrMCVQ",
        "outputId": "cb195e90-b35e-4b31-f5c0-8d42ee65286b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30:\tloss_train = 2.20;\tloss_valid = 2.05;\tf1_valid = 0.26;\n",
            "Epoch 2/30:\tloss_train = 1.91;\tloss_valid = 1.84;\tf1_valid = 0.64;\n",
            "Epoch 3/30:\tloss_train = 1.82;\tloss_valid = 1.80;\tf1_valid = 0.64;\n",
            "Epoch 4/30:\tloss_train = 1.78;\tloss_valid = 1.77;\tf1_valid = 0.64;\n",
            "Epoch 5/30:\tloss_train = 1.75;\tloss_valid = 1.74;\tf1_valid = 0.64;\n",
            "Epoch 6/30:\tloss_train = 1.73;\tloss_valid = 1.73;\tf1_valid = 0.79;\n",
            "Epoch 7/30:\tloss_train = 1.72;\tloss_valid = 1.71;\tf1_valid = 0.79;\n",
            "Epoch 8/30:\tloss_train = 1.71;\tloss_valid = 1.70;\tf1_valid = 0.79;\n",
            "Epoch 9/30:\tloss_train = 1.70;\tloss_valid = 1.70;\tf1_valid = 0.81;\n",
            "Epoch 10/30:\tloss_train = 1.69;\tloss_valid = 1.69;\tf1_valid = 0.81;\n",
            "Epoch 11/30:\tloss_train = 1.69;\tloss_valid = 1.69;\tf1_valid = 0.81;\n",
            "Epoch 12/30:\tloss_train = 1.68;\tloss_valid = 1.68;\tf1_valid = 0.81;\n",
            "Epoch 13/30:\tloss_train = 1.68;\tloss_valid = 1.68;\tf1_valid = 0.81;\n",
            "Epoch 14/30:\tloss_train = 1.68;\tloss_valid = 1.68;\tf1_valid = 0.81;\n",
            "Epoch 15/30:\tloss_train = 1.68;\tloss_valid = 1.68;\tf1_valid = 0.81;\n",
            "Epoch 16/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.81;\n",
            "Epoch 17/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.81;\n",
            "Epoch 18/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.81;\n",
            "Epoch 19/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.81;\n",
            "Epoch 20/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.81;\n",
            "Epoch 21/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.81;\n",
            "Epoch 22/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.81;\n",
            "Epoch 23/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.81;\n",
            "Epoch 24/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.81;\n",
            "Epoch 25/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.81;\n",
            "Epoch 26/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.81;\n",
            "Epoch 27/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.81;\n",
            "Epoch 28/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.81;\n",
            "Epoch 29/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.81;\n",
            "Epoch 30/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.81;\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='epoch', ylabel='loss'>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# instantiate model and move to device:\n",
        "model = CustomNetwork().to(device)\n",
        "\n",
        "# train model:\n",
        "history = fit(model, loader_train, loader_valid, epochs=30, lr=.01)\n",
        "\n",
        "# plot history:\n",
        "history[['loss_train', 'loss_valid']].plot(xlabel='epoch', ylabel='loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qmHUt5M_nQd"
      },
      "source": [
        "**Evaluation**: `evaluate` will return the metric scores!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMdArSMDi8BI",
        "outputId": "a9995bd0-bb65-4342-fc37-ff36f8261896"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.7291666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "evaluate(model, loader_test) #evaluate on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0KyvGWMmnm6"
      },
      "source": [
        "How does SGD work?\n",
        "\n",
        "<img src=\"https://pantelis.github.io/cs677/docs/common/lectures/optimization/sgd/images/gradient-descent.png\" alt=\"gradient-descent.png\" style=\"width:500px;\"/>\n",
        "\n",
        "Can be improved by:\n",
        " - ... reducing the stepsize (i.e. `lr`) towards the end\n",
        " - ... using momentum to keep a clear trajectory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcSUB0uJTPBg"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 4</b> - Improved Training:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Improve the above training loop with the following steps:\n",
        "1. replace the very basic SGD optimizer with the momentum-based [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer. Compare how the learning curves change after this step. **As ADAM is more sensitive to the learning rate, set it to `0.001` after changing the optimizer!**\n",
        "2. add a [`torch.optim.lr_scheduler.LinearLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LinearLR.html) scheduler (_start: `1.0*lr`, end:`0.33*lr`, over 10 epochs_).  Compare how the learning curves change after this step.\n",
        "3. add an **early stopping** functionality, that stops training when the validation loss has not improved for `patience` epochs and restores the model parameters to the ones achieving the best loss. **Use a patience of `5` to retrain the network.**\n",
        "\n",
        "**Disclaimer:** *We will not check whether you actually compare the loss curves before and after adding a specific step. But we may ask about their impact in the final exam.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from typing import Optional, Callable\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LinearLR"
      ],
      "metadata": {
        "id": "HrHzxYJV3SfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pwOaMCDSTOpS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "38f97127-5bec-4fac-e42e-b50eddc4db9d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CustomNetwork' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f3945638a970>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCustomNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CustomNetwork' is not defined"
          ]
        }
      ],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  model.train()\n",
        "  losses = [] if loss_fn is not None else None\n",
        "\n",
        "  with pt.enable_grad():\n",
        "    for X_batch, y_batch in loader_train:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(X_batch)\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if losses is not None:\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "\n",
        "  return np.mean(losses) if losses is not None else None\n",
        "\n",
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "  model.eval()\n",
        "  labels = []\n",
        "  predictions = []\n",
        "  losses = [] if loss_fn is not None else None\n",
        "\n",
        "  with pt.no_grad():\n",
        "    for X_batch, y_batch in loader_valid:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      y_pred = model(X_batch)\n",
        "      labels.extend(y_batch.cpu().numpy())\n",
        "      predictions.extend(y_pred.cpu().numpy())\n",
        "\n",
        "      if loss_fn is not None:\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "\n",
        "  f1 = f1_score(\n",
        "    np.array(labels),\n",
        "    np.argmax(np.array(predictions), axis=1),\n",
        "    average='macro'\n",
        "  )\n",
        "\n",
        "  if loss_fn is None:\n",
        "    return {'f1': f1}\n",
        "  else:\n",
        "    return {'loss': np.mean(losses), 'f1': f1}\n",
        "\n",
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float, patience:int):\n",
        "  optimizer = pt.optim.Adam(model.parameters(), lr=lr)\n",
        "  scheduler = pt.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.33, total_iters=10)\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  best_loss = float('inf')\n",
        "  best_state = None\n",
        "  wait = 0\n",
        "\n",
        "  history = []\n",
        "\n",
        "  for i in range(epochs):\n",
        "    loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "    metrics = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "    history.append({\n",
        "      'loss_train': loss_train,\n",
        "      'loss_valid': metrics['loss'],\n",
        "      'f1_valid': metrics['f1']\n",
        "    })\n",
        "\n",
        "    if metrics['loss'] < best_loss:\n",
        "      best_loss = metrics['loss']\n",
        "      best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "      wait = 0\n",
        "    else:\n",
        "      wait += 1\n",
        "      if wait >= patience:\n",
        "        break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "  if best_state is not None:\n",
        "    model.load_state_dict(best_state)\n",
        "\n",
        "  return pd.DataFrame(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r-hDPkRUY0R"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 4. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKm2rIvKUP2C"
      },
      "source": [
        "### Section 4: Other useful and frequently used functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp4BHXYqUWBH"
      },
      "source": [
        "Save and load the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBmnCPTdaAlV"
      },
      "source": [
        "**Option 1:** `torch.save(...)` / `torch.load(...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQIhSX16UXpR"
      },
      "outputs": [],
      "source": [
        "pt.save(model, 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrmRkkvbVYqj",
        "outputId": "90d27545-4d7e-4b61-c18f-9b23de1736ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  model.pt\n",
            " extracting: model/data.pkl          \n",
            " extracting: model/byteorder         \n",
            " extracting: model/data/0            \n",
            " extracting: model/data/1            \n",
            " extracting: model/data/2            \n",
            " extracting: model/data/3            \n",
            " extracting: model/version           \n",
            " extracting: model/.data/serialization_id  \n"
          ]
        }
      ],
      "source": [
        "# this saves a zipfile!\n",
        "!unzip model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sexXOBTKUZH_",
        "outputId": "b2925d49-7bf5-47a0-b6a2-02bd6c086ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "            Linear-2                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = pt.load('model.pt', weights_only=False) # \"weights_only = True\" only loads PyTorch Tensors in the model file!\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr88yK-8Z5GY"
      },
      "source": [
        "**Option 2:** save/load state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsXhrkFhZ9NY"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44MB9qujUPys"
      },
      "outputs": [],
      "source": [
        "with open('model_state_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(model.state_dict(), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CuVaeSJZgW0",
        "outputId": "3cf55e12-b6ab-424b-ac36-1ad05defb9f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "            Linear-2                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "with open('model_state_dict.pkl', 'rb') as f:\n",
        "  state_dict = pickle.load(f)\n",
        "model.load_state_dict(state_dict)\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w003CKN5R7vY"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 5</b> - Regression MLP</span>\n",
        "\n",
        "---\n",
        "\n",
        "We have created a classification model on Fashion MNIST with PyTorch. In addition, we can of course use similar PyTorch models to solve regression tasks. **How can we do that?** Which part should we change to make it work on regression tasks? That would be our last task in this lab. Based on your knowledge from the second lecture, you may be able to figure out which part you need to change.\n",
        "\n",
        "Create a regression model by adapting the PyTorch model we used above and train it on the [california housing dataset](https://nextilearn.dsv.su.se/mod/resource/view.php?id=25386 ).\n",
        "You may need to change **a loss function** and input / output layers as we no longer deal with images and classification. Feel free to use scikit-learn but we still recommend you to practice preprocessing with NumPy for your skills.\n",
        "\n",
        "**Upload the resulting predictions to NextIlearn. Your model should achieve an MSE < XXX to pass.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qforG1NGbEuq"
      },
      "source": [
        "1. Get training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "YpmUlavla3Py",
        "outputId": "8241a80b-6bbd-481c-eb94-0ab32d398a89",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open data.zip, data.zip.zip or data.zip.ZIP.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/task5'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-174-d8bf59d8065a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 1.3 check files:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/task5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/task5'"
          ]
        }
      ],
      "source": [
        "# 1.1 you should have received a zip folder \"data.zip\" along with this notebook\n",
        "\n",
        "# 1.2 unzip data.zip\n",
        "!unzip data.zip\n",
        "\n",
        "# 1.3 check files:\n",
        "os.listdir('data/task5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYYglS3ybCM8"
      },
      "source": [
        "2. Create Data Pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch as pt\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "chWvk_zi5OQ2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NQ_Rj925R7vY"
      },
      "outputs": [],
      "source": [
        "# 2.1 load training data:\n",
        "data_train = pd.read_csv('data_train.csv', index_col=0)\n",
        "labels_train = pd.read_csv('labels_train.csv', index_col=0)\n",
        "\n",
        "# 2.2 load test data (no labels):\n",
        "data_test = pd.read_csv('data_test.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(data_train.values)\n",
        "X_test = scaler.transform(data_test.values)\n",
        "y_train = labels_train.values.astype(np.float32)\n",
        "\n",
        "# Convert to tensors\n",
        "tensor_x = pt.tensor(X_train, dtype=pt.float32)\n",
        "tensor_y = pt.tensor(y_train, dtype=pt.float32).squeeze()\n",
        "train_dataset = TensorDataset(tensor_x, tensor_y)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Convert test data\n",
        "tensor_test = pt.tensor(X_test, dtype=pt.float32)\n"
      ],
      "metadata": {
        "id": "pVwfG0QnKDMo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaRz2hDYbYJ6"
      },
      "source": [
        "3. Create Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nl0-sMfCR7vZ"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(8, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzSyLqesbkYc"
      },
      "source": [
        "4. Train model on `data_train` and `labels_train`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_dqM_Yzyb1ho"
      },
      "outputs": [],
      "source": [
        "# Training setup\n",
        "model = RegressionModel()\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = pt.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "def train(model, loader, optimizer, loss_fn, epochs=100):\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for X_batch, y_batch in loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ipIi84zb5ZR"
      },
      "source": [
        "5. Predict `data_test` and save predictions to `submission.csv`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "V_gqdJvucm2l"
      },
      "outputs": [],
      "source": [
        "# Train and predict\n",
        "train(model, train_loader, optimizer, loss_fn, epochs=100)\n",
        "model.eval()\n",
        "with pt.no_grad():\n",
        "    predictions = model(tensor_test).numpy()\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame(predictions, columns=['predictions'])\n",
        "submission.to_csv('submission.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('submission.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L02CCxxXOuF5",
        "outputId": "cc4ee6e9-f591-4e86-8fdb-5bbdde133509"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  predictions\n",
            "0           0     2.044809\n",
            "1           1     3.918509\n",
            "2           2     4.344497\n",
            "3           3     0.743609\n",
            "4           4     2.909510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Chd7CnHv7tWS",
        "outputId": "dab31e59-de33-49ce-edb9-23f0e3eceafd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6d7e0845-bbec-4d60-9014-1ab1edb170f8\", \"submission.csv\", 60264)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB-ezFJER7vZ"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 5. Upload your final predictions (the file* `submission.csv` *) to **Homework 2 - Code** on **NextIlearn***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}